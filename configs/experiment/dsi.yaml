# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /datamodule: seq2seq.yaml
  - override /model: seq2seq.yaml
  - override /callbacks: default.yaml
  - override /trainer: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["seq2seq", "t5_model"]

seed: 17

# trainer:
#   min_epochs: 10
#   max_epochs: 10
#   gradient_clip_val: 0.5

# model:
#   optimizer:
#     lr: 0.002
#   net:
#     lin1_size: 128
#     lin2_size: 256
#     lin3_size: 64

# datamodule:
#   batch_size: 64

# logger:
#   wandb:
#     tags: ${tags}
#     group: "seq2seq"
